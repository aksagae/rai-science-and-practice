---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

#layout: home
title: RAI in the Generative Era, Science and Practice
---


## Abstract
Generative AI brings additional nuance to the challenges of Responsible AI (RAI). These challenges include some that were common before generative AI, such as bias and explainability, and some that are unique to generative models, including hallucination, toxicity, and intellectual property protection. This tutorial is structured around hands-on exercises that let participants engage with large language models and with each other, to explore specific strategies that they can apply in their own RAI work. We will compare the challenges of traditional vs. generative RAI, and align those challenges with best practices for (and by) industry practitioners to assess and minimize RAI risk. Together with participants, we will test RAI guardrails in a jailbreaking game and conduct a structured risk assessment for a realistic use case, automatic generation of product descriptions.

## Important Dates

This tutorial will be delivered at [FAccT 2024](https://facctconference.org/2024/)

| Event                 | Day              |   Time        |
|:----------------------|:----------------:|:-------------:|
| FAccT Conference      | June 3-6, 2024   |               |
| Tutorial 3            | Tue, June 4      |17:25-18:25 BRT|

## Resources

### The Risk Tolerance Game

In this exercise, we explore use cases for generative AI and compare our appetite for risk in each case. Cultural, geographic, and organizational contexts can all affect how we perceive the risk of AI applications. This exercise prompts us to discuss perceptions and their effect on RAI practice. Discussion topics will be posted to [slido.com](https://www.slido.com)

### The Jailbreak Game

In this exercise, we compare the RAI compliance of two chat bots: bot A is an LLM playground, with no use case restrictions; bot B is constrained to a specific use case. 

Participants team up to test a list of prompts against both bots. Try to elicit stereotyped, toxic, or non-factual information. This hands-on exercise reveals the impact of use case definitions on RAI risk.

* Access chat bots from the [cloudfront UI (link TBD)]()
* View some sample prompts on our [sample prompts page](sample_prompts)


### The Risk Assessment Framework

Principled risk assessment is an entry point into RAI practice. In this exercise, we apply a NIST-compliant assessment framework to a generative AI use case. 

## Contributors
Alicia Sagae, Amazon AWS AI

Nil-Jana Akpinar, Amazon AWS AI

Mia Mayer, Amazon AWS AI

Riccardo Fogliato, Amazon AWS AI

Michael Kearns, Amazon AWS AI and University of Pennsylvania

